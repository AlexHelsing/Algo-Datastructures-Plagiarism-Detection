Plagiarism detection
====================

Time spent per group member:
* Stefan Ingimarsson 12hrs
* Henrik: 11 hrs
* Alexander Helsing: 11hrs

Task 1: Analyzing the slow program
----------------------------------

**Question**
What is the asymptotic complexity of findSimilarity?
Answer in terms of N, the total number of 5-grams in the input files.
Assume that the number of duplicate occurrences of 5-grams is a small constant - that is, there is not much plagiarised text.
Explain briefly.

The complexity for buildindex should be O(1) and findsimilairity should be o(n^2 * k^2).

findsimilairity: n is the number of files and k is the length of ngrams. there are two nested loops
iterating all over the files and within those two nested loops there are two more nested loops.

buildindex: it just creates an empty bst and returns without doing much else.

TODO

**Question**
How long did the program take on the 'small' and 'medium' directories?
Is the ratio between the times what you would expect,
given the asymptotic complexity? Explain very briefly why.

Give the path to the document set: documents/small
Reading all input files took 0,06 seconds.
Building n-gram index took 0,00 seconds.
Computing similarity scores took 2,74 seconds.
Finding the most similar files took 0,01 seconds.
In total the program took 2,80 seconds.

And:

Reading all input files took 0,20 seconds.
Building n-gram index took 0,00 seconds.
Computing similarity scores took 565,77 seconds.
Finding the most similar files took 0,02 seconds.
In total the program took 565,99 seconds.

Since the complexity is quadratic and the medium file is 10 times the size of the small file, we were not
surprised that it took ca 566 seconds.


TODO

**Question**
How long do you predict the program would take to run on
the 'huge' directory? Show your calculations.

565.99 seconds to do the medium file. The huge file is 20 times larger. Therefore, we
multiply 565.99 x 20 = 11319,8 seconds.

We predict it will take approximately 2,5 hours for the program to run the 'huge' directory.

TODO

Task 2: Using an index
----------------------

**Question**
Which of the three BSTs in the program usually become unbalanced?
Say very briefly:
- how you observed this,
- why you think this is the case.

Nonbalancing BSTs usually become unbalanced when it comes to the larger directories.
A nonbalancing tree is not designed to balance itself automatically. This means that
if the data being inserted into the tree is not added in a balanced manner, the tree
can become unbalanced.

TODO

**Question** (optional)
Is there a simple way to stop these trees becoming unbalanced?

TODO (optional)

Task 3: Using scapegoat trees instead of BSTs
---------------------------------------------

For the below questions, we denote by N the total number of 5-grams.
We assume there is a (small) constant number of duplicate occurrences of 5-grams.

**Question**
What is the asymptotic complexity of buildIndex?
Justify briefly.
O(nm) where n is the number of documents and m is the number of 5grams per document. the outer loop
iterates over n and the inner loop iterates over m.

TODO

**Question**
What is the asymptotic complexity of findSimilarity?
Justify briefly.
O(n^2) where n is the total number of ngrams in the document set. because there are two nested loops
that iterate over all the files in the input.

TODO

**Question** (optional)
Instead of the previous assumption, we now allow an arbitrary total similarity score S.
Express the asymptotic complexity of the two functions in terms of both N and S (at the same time).

TODO (optional)

Appendix: general information
=============================

**Question**
Do you know of any bugs or limitations?

TODO

**Question**
Did you collaborate with any other students on this lab?
If so, write with whom and in what way you collaborated.
Also list any resources (including the web) you have used in creating your design.

TODO

**Question**
Did you encounter any serious problems?

Not really, no.

TODO

**Question**
What is your feedback on this assignment?
-It was pretty confusing at first with ngrams and what we actually needed to do in task 2.
However once we understood everything, things got a little easier.
-Extremely challenging but very informative. It has given several 'aha' moments when one
 finally understands a concept.

TODO

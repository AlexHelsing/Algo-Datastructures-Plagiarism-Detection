Plagiarism detection
====================

Time spent per group member:
* Stefan Ingimarsson 12hrs
* TODO: TODO
* TODO: TODO

Task 1: Analyzing the slow program
----------------------------------

**Question**
What is the asymptotic complexity of findSimilarity?
Answer in terms of N, the total number of 5-grams in the input files.
Assume that the number of duplicate occurrences of 5-grams is a small constant - that is, there is not much plagiarised text.
Explain briefly.

The complexity for buildindex should be O(nm(log(n)) and findsimilairity should be o(n^2. The outer
loop runs through the files x amount of times, the second loop also iterates through the files, except
the current file being processed by the outer loop, so it runs x-1 times. The two inner loops run through
all the ngrams in each file y times. In the end the total number of the two inner loops is about x^2*y^2
which should be n^2.

TODO

**Question**
How long did the program take on the 'small' and 'medium' directories?
Is the ratio between the times what you would expect,
given the asymptotic complexity? Explain very briefly why.

Give the path to the document set: documents/small
Reading all input files took 0,06 seconds.
Building n-gram index took 0,00 seconds.
Computing similarity scores took 2,74 seconds.
Finding the most similar files took 0,01 seconds.
In total the program took 2,80 seconds.

And:

Reading all input files took 0,20 seconds.
Building n-gram index took 0,00 seconds.
Computing similarity scores took 565,77 seconds.
Finding the most similar files took 0,02 seconds.
In total the program took 565,99 seconds.


TODO

**Question**
How long do you predict the program would take to run on
the 'huge' directory? Show your calculations.

TODO

Task 2: Using an index
----------------------

**Question**
Which of the three BSTs in the program usually become unbalanced?
Say very briefly:
- how you observed this,
- why you think this is the case.

TODO

**Question** (optional)
Is there a simple way to stop these trees becoming unbalanced?

TODO (optional)

Task 3: Using scapegoat trees instead of BSTs
---------------------------------------------

For the below questions, we denote by N the total number of 5-grams.
We assume there is a (small) constant number of duplicate occurrences of 5-grams.

**Question**
What is the asymptotic complexity of buildIndex?
Justify briefly.
O(n log(n)

TODO

**Question**
What is the asymptotic complexity of findSimilarity?
Justify briefly.
O(n log(n)

TODO

**Question** (optional)
Instead of the previous assumption, we now allow an arbitrary total similarity score S.
Express the asymptotic complexity of the two functions in terms of both N and S (at the same time).

TODO (optional)

Appendix: general information
=============================

**Question**
Do you know of any bugs or limitations?

TODO

**Question**
Did you collaborate with any other students on this lab?
If so, write with whom and in what way you collaborated.
Also list any resources (including the web) you have used in creating your design.

TODO

**Question**
Did you encounter any serious problems?

TODO

**Question**
What is your feedback on this assignment?
-It was pretty confusing at first with ngrams and what we actually needed to do in task 2. However once we understood everything, things got a little easier.

TODO
